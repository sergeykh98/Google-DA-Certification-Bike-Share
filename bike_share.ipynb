{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Transformation of Cyclistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background & Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__Cyclistic__*: A bike-share program that features more than 5,800 bicycles and a network of 692 docking stations across Chicago. That provides access to bikes that can be unlocked from one station and returned to any other station in the system. Likewise, setting itself apart by offering reclining bikes, hand tricycles, and cargo bikes, making bike-share more inclusive to people with disabilities and riders who can’t use a standard two-wheeled bike.\n",
    "\n",
    "Cyclistic users generally purchase single-ride passes, full-day passes, and annual memberships to ride for leisure, explore the city or commute to work each day. Thus we want explore how annual members and casual riders use Cyclistic bikes diferently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KPI's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What day of the week are the bikes are rented?\n",
    "2. What time of day are the bikes being rented the most?\n",
    "3. Does season’s have an effect on bikes renting?\n",
    "4. Which area has the most renting recorded? (Suburban, Commercial, Private Area, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we will use data [__Cyclistic's historicical trip data__](https://divvy-tripdata.s3.amazonaws.com/index.html) from 2019. The data also include the following fields:\n",
    "\n",
    "| Field             | Description                                  |\n",
    "|----------------|----------------------------------------------------------------------------------------------|\n",
    "| trip_id           | Unique identifier of renting transcation     |\n",
    "| start_time        | Date and time when bikes are rented          |\n",
    "| end_time          | Date and time when bikes are returned        |\n",
    "| bikeid            | Unique identifier of each bike               |\n",
    "| tripduration      | Total rent duration in seconds               |\n",
    "| from_station_id   | Station ID where bikes where rented          |\n",
    "| from_station_name | Station name where bikes where rented        |\n",
    "| to_station_id     | Station ID where bikes where returned        |     \n",
    "| to_station_name   | Station name where bikes where returned      |\n",
    "| usertype          | Type of the riders or bike users             |\n",
    "| gender            | Gender of annual members or subscribers      |\n",
    "| birthyear         | Age of the annual members or subscribers     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Primary Modules\n",
    "The program heavily relies on [**pandas**](http://pandas.pydata.org/), [**geopy**](https://geopy.readthedocs.io/en/stable/) and [**datetime**](https://docs.python.org/3/library/datetime.html) for data wrangling and transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "from time import sleep\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting csv files from 4 quartiles into separate dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = pd.read_csv(\"data/Divvy_Trips_2019_Q1.csv\")\n",
    "q2 = pd.read_csv(\"data/Divvy_Trips_2019_Q2.csv\")\n",
    "q3 = pd.read_csv(\"data/Divvy_Trips_2019_Q3.csv\")\n",
    "q4 = pd.read_csv(\"data/Divvy_Trips_2019_Q4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#q4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming q2 column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that the columns for 2nd quartile have different column names, the following lines of code renames them to match other dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_col = []\n",
    "for col in q1.columns:\n",
    "    q1_col.append(col)\n",
    "q2_col = []\n",
    "for col in q2.columns:\n",
    "    q2_col.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.rename(columns=dict(zip(q2_col, q1_col)), inplace=True)\n",
    "#q2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all dataframes into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>bikeid</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_id</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>to_station_id</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>usertype</th>\n",
       "      <th>gender</th>\n",
       "      <th>birthyear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21742443</td>\n",
       "      <td>2019-01-01 00:04:37</td>\n",
       "      <td>2019-01-01 00:11:07</td>\n",
       "      <td>2167</td>\n",
       "      <td>390.0</td>\n",
       "      <td>199</td>\n",
       "      <td>Wabash Ave &amp; Grand Ave</td>\n",
       "      <td>84</td>\n",
       "      <td>Milwaukee Ave &amp; Grand Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1989.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21742444</td>\n",
       "      <td>2019-01-01 00:08:13</td>\n",
       "      <td>2019-01-01 00:15:34</td>\n",
       "      <td>4386</td>\n",
       "      <td>441.0</td>\n",
       "      <td>44</td>\n",
       "      <td>State St &amp; Randolph St</td>\n",
       "      <td>624</td>\n",
       "      <td>Dearborn St &amp; Van Buren St (*)</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Female</td>\n",
       "      <td>1990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21742445</td>\n",
       "      <td>2019-01-01 00:13:23</td>\n",
       "      <td>2019-01-01 00:27:12</td>\n",
       "      <td>1524</td>\n",
       "      <td>829.0</td>\n",
       "      <td>15</td>\n",
       "      <td>Racine Ave &amp; 18th St</td>\n",
       "      <td>644</td>\n",
       "      <td>Western Ave &amp; Fillmore St (*)</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Female</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21742446</td>\n",
       "      <td>2019-01-01 00:13:45</td>\n",
       "      <td>2019-01-01 00:43:28</td>\n",
       "      <td>252</td>\n",
       "      <td>1,783.0</td>\n",
       "      <td>123</td>\n",
       "      <td>California Ave &amp; Milwaukee Ave</td>\n",
       "      <td>176</td>\n",
       "      <td>Clark St &amp; Elm St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21742447</td>\n",
       "      <td>2019-01-01 00:14:52</td>\n",
       "      <td>2019-01-01 00:20:56</td>\n",
       "      <td>1170</td>\n",
       "      <td>364.0</td>\n",
       "      <td>173</td>\n",
       "      <td>Mies van der Rohe Way &amp; Chicago Ave</td>\n",
       "      <td>35</td>\n",
       "      <td>Streeter Dr &amp; Grand Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704049</th>\n",
       "      <td>25962900</td>\n",
       "      <td>2019-12-31 23:56:13</td>\n",
       "      <td>2020-01-01 00:15:45</td>\n",
       "      <td>2196</td>\n",
       "      <td>1,172.0</td>\n",
       "      <td>112</td>\n",
       "      <td>Green St &amp; Randolph St</td>\n",
       "      <td>225</td>\n",
       "      <td>Halsted St &amp; Dickens Ave</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1981.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704050</th>\n",
       "      <td>25962901</td>\n",
       "      <td>2019-12-31 23:56:34</td>\n",
       "      <td>2020-01-01 00:22:08</td>\n",
       "      <td>4877</td>\n",
       "      <td>1,533.0</td>\n",
       "      <td>90</td>\n",
       "      <td>Millennium Park</td>\n",
       "      <td>90</td>\n",
       "      <td>Millennium Park</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1992.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704051</th>\n",
       "      <td>25962902</td>\n",
       "      <td>2019-12-31 23:57:05</td>\n",
       "      <td>2020-01-01 00:05:46</td>\n",
       "      <td>863</td>\n",
       "      <td>520.0</td>\n",
       "      <td>623</td>\n",
       "      <td>Michigan Ave &amp; 8th St</td>\n",
       "      <td>52</td>\n",
       "      <td>Michigan Ave &amp; Lake St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704052</th>\n",
       "      <td>25962903</td>\n",
       "      <td>2019-12-31 23:57:11</td>\n",
       "      <td>2020-01-01 00:05:45</td>\n",
       "      <td>2637</td>\n",
       "      <td>514.0</td>\n",
       "      <td>623</td>\n",
       "      <td>Michigan Ave &amp; 8th St</td>\n",
       "      <td>52</td>\n",
       "      <td>Michigan Ave &amp; Lake St</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Female</td>\n",
       "      <td>1970.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704053</th>\n",
       "      <td>25962904</td>\n",
       "      <td>2019-12-31 23:57:17</td>\n",
       "      <td>2019-12-31 23:59:18</td>\n",
       "      <td>5930</td>\n",
       "      <td>120.0</td>\n",
       "      <td>256</td>\n",
       "      <td>Broadway &amp; Sheridan Rd</td>\n",
       "      <td>240</td>\n",
       "      <td>Sheridan Rd &amp; Irving Park Rd</td>\n",
       "      <td>Subscriber</td>\n",
       "      <td>Male</td>\n",
       "      <td>1982.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3818004 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         trip_id           start_time             end_time  bikeid  \\\n",
       "0       21742443  2019-01-01 00:04:37  2019-01-01 00:11:07    2167   \n",
       "1       21742444  2019-01-01 00:08:13  2019-01-01 00:15:34    4386   \n",
       "2       21742445  2019-01-01 00:13:23  2019-01-01 00:27:12    1524   \n",
       "3       21742446  2019-01-01 00:13:45  2019-01-01 00:43:28     252   \n",
       "4       21742447  2019-01-01 00:14:52  2019-01-01 00:20:56    1170   \n",
       "...          ...                  ...                  ...     ...   \n",
       "704049  25962900  2019-12-31 23:56:13  2020-01-01 00:15:45    2196   \n",
       "704050  25962901  2019-12-31 23:56:34  2020-01-01 00:22:08    4877   \n",
       "704051  25962902  2019-12-31 23:57:05  2020-01-01 00:05:46     863   \n",
       "704052  25962903  2019-12-31 23:57:11  2020-01-01 00:05:45    2637   \n",
       "704053  25962904  2019-12-31 23:57:17  2019-12-31 23:59:18    5930   \n",
       "\n",
       "       tripduration  from_station_id                    from_station_name  \\\n",
       "0             390.0              199               Wabash Ave & Grand Ave   \n",
       "1             441.0               44               State St & Randolph St   \n",
       "2             829.0               15                 Racine Ave & 18th St   \n",
       "3           1,783.0              123       California Ave & Milwaukee Ave   \n",
       "4             364.0              173  Mies van der Rohe Way & Chicago Ave   \n",
       "...             ...              ...                                  ...   \n",
       "704049      1,172.0              112               Green St & Randolph St   \n",
       "704050      1,533.0               90                      Millennium Park   \n",
       "704051        520.0              623                Michigan Ave & 8th St   \n",
       "704052        514.0              623                Michigan Ave & 8th St   \n",
       "704053        120.0              256               Broadway & Sheridan Rd   \n",
       "\n",
       "        to_station_id                 to_station_name    usertype  gender  \\\n",
       "0                  84       Milwaukee Ave & Grand Ave  Subscriber    Male   \n",
       "1                 624  Dearborn St & Van Buren St (*)  Subscriber  Female   \n",
       "2                 644   Western Ave & Fillmore St (*)  Subscriber  Female   \n",
       "3                 176               Clark St & Elm St  Subscriber    Male   \n",
       "4                  35         Streeter Dr & Grand Ave  Subscriber    Male   \n",
       "...               ...                             ...         ...     ...   \n",
       "704049            225        Halsted St & Dickens Ave  Subscriber    Male   \n",
       "704050             90                 Millennium Park  Subscriber    Male   \n",
       "704051             52          Michigan Ave & Lake St  Subscriber    Male   \n",
       "704052             52          Michigan Ave & Lake St  Subscriber  Female   \n",
       "704053            240    Sheridan Rd & Irving Park Rd  Subscriber    Male   \n",
       "\n",
       "        birthyear  \n",
       "0          1989.0  \n",
       "1          1990.0  \n",
       "2          1994.0  \n",
       "3          1993.0  \n",
       "4          1994.0  \n",
       "...           ...  \n",
       "704049     1981.0  \n",
       "704050     1992.0  \n",
       "704051     1967.0  \n",
       "704052     1970.0  \n",
       "704053     1982.0  \n",
       "\n",
       "[3818004 rows x 12 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([q1, q2, q3, q4], axis=0,sort=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resetting Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = np.arange(1,len(df)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing column datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.convert_dtypes()\n",
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of separates start and end time into subsiquent dimensions: month, weekday, and hourtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_data(df_col, list_name, data_variable):\n",
    "    for row in df_col:\n",
    "        date = datetime.strptime(row, \"%Y-%m-%d %H:%M:%S\")\n",
    "        if data_variable == \"h\":\n",
    "            list_name.append(date.hour)\n",
    "        elif data_variable == \"wd\":\n",
    "            list_name.append(calendar.day_name[date.weekday()])\n",
    "        elif data_variable == \"m\":\n",
    "            list_name.append(date.strftime(\"%B\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_list = []\n",
    "time_data(df['start_time'], hour_list, \"h\")\n",
    "weekday_list = []\n",
    "time_data(df['start_time'], weekday_list, \"wd\")\n",
    "month_list = [] \n",
    "time_data(df['start_time'], month_list, \"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time(hour)'] = hour_list\n",
    "df['Weekday'] = weekday_list\n",
    "df['Month'] = month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bike_share.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting geocoordinates of each station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the geopy library, the following lines of code extract the latitude and longitude of each rental station. The dataset contains over 3 million records, the approximate extraction of geodata using an API for each station may take hours and days.  Thus, considering that station name may certainly overlap, the data processing will be divided into the following steps:\n",
    "* __Step 1__: Removing strings and characters from both __station_name__ columns that may impact the search.\n",
    "* __Step 2__: Extract unique/distinc station names into new list. \n",
    "* __Step 3__: Using the __geopy API__ extract latitude and longitude into separate lists.\n",
    "* __Step 4__: Combine station, latitude, and longitude into dataframe and/or dictionary.\n",
    "* __Step 5__: Using for loop get coordinates for each record where station_names match. (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Removing strings and characters from both columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['from_station_name'] = df['from_station_name'].str.strip('(*)')\n",
    "df['from_station_name'] = df['from_station_name'].str.strip(\"(Temp)\")\n",
    "df['to_station_name'] = df['to_station_name'].str.strip('(*)')\n",
    "df['to_station_name'] = df['to_station_name'].str.strip(\"(Temp)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Extract unique/distinc station names into new list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_station_name(list1, unique_list):\n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_station = []\n",
    "unique_station_name(df['from_station_name'],unique_station)\n",
    "unique_station_name(df['to_station_name'],unique_station)\n",
    "#unique_station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "641"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Extracting latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_coordinates(station, lat, long, user_agent):\n",
    "    geolocator = Nominatim(user_agent=user_agent)\n",
    "    for row in station:\n",
    "        try:\n",
    "            location = geolocator.geocode(row)\n",
    "            lat.append(location.latitude)\n",
    "            long.append(location.longitude)\n",
    "        except:\n",
    "            lat.append(None)\n",
    "            long.append(None)\n",
    "            sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude = []\n",
    "longitude = []\n",
    "geo_coordinates(unique_station, latitude, longitude, \"bike_share\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Combine station, latitude, and longitude into dataframe and/or dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary\n",
    "station_location =[{'name': name, 'lat': lat, 'long': long} for name,lat,long in zip(unique_station,latitude,latitude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe\n",
    "station_df = pd.DataFrame()\n",
    "station_df['station_name'] = unique_station\n",
    "station_df['lat'] = latitude\n",
    "station_df['long'] = longitude\n",
    "station_df.to_csv('station_geodata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Using loop get coordinates for each record where station_names match. (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def station_coordinates(df, station_dict, list_lat, list_long):\n",
    "    for row in df:\n",
    "        for s in range(0,len(station_dict)):\n",
    "            if row == station_dict[s]['name']:\n",
    "                list_lat.append(station_dict[s]['lat'])\n",
    "                list_long.append(station_dict[s]['long'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_lat = []\n",
    "start_long = []\n",
    "station_coordinates(df['from_station_name'], station_location, start_lat, start_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_lat = []\n",
    "end_long = []\n",
    "station_coordinates(df['to_station_name'], station_location, end_lat, end_long)\n",
    "#station_coordinates(df, station_location, end_lat, end_long, 'to_station_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['start_lat'] = start_lat\n",
    "df['start_long'] = start_long\n",
    "df['end_lat'] = end_lat\n",
    "df['end_long'] = end_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bike_share_with_geodata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data visualization dashboard and PowerPoint has been created using __Tableau__ and can be found using the following links:\n",
    "* __Github__: [click here](https://github.com/sergeykh98/Google-DA-Certification-Bike-Share)\n",
    "* __Tableau Public__: [click here](https://public.tableau.com/app/profile/sergey.khegay/viz/Cyclisticbike-sharedashboard/Cyclisticbike-sharedashboard)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
